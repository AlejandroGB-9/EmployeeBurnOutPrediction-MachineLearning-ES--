{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grupo 9 Práctica 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook de la práctica 2 realizado por Alejandro García Berrocal (100451059) y Lucas Gallego Bravo (100429005)\n",
    "GitHub: https://github.com/AlejandroGB-9/Grupo9-Practica2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prerequisitos:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Librerías e imports necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install pandas\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install scikit-optimize\n",
    "!pip3 install skopt\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install statsmodels\n",
    "!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, confusion_matrix, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_pickle('./attrition_available_9.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este EDA se han analizado los datos provenientes del archivo attrition_available_9.pkl, el cual contiene los datos de los empleados de una empresa. En este EDA se han analizado los datos de los empleados que han abandonado la empresa, es decir, aquellos que tienen el valor 1 en la columna Attrition. Aparte de realizar ese estudio se ha realizado un estudio de la correlación entre las variables numéricas y se ha realizado un estudio de los datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "#Cuantos datos faltantes o NaN hay\n",
    "\n",
    "print(datos.head())\n",
    "print()\n",
    "print(\"Información del dataset:\\n \", datos.info())\n",
    "print()\n",
    "print(datos['Attrition'].value_counts(normalize=True))\n",
    "print()\n",
    "print(\"Suma de datos que son nulos o NA:\\n\", datos.isnull().sum())\n",
    "print()\n",
    "print(f\"Cuantos valores NaN|missing values contiene el target: {datos['Attrition'].isnull().sum()}\")\n",
    "print()\n",
    "print(f\"Tiene el mismo valor en todas las filas el atributo Over18: {datos['Over18'].value_counts()/len(datos)}\")\n",
    "print()\n",
    "\n",
    "#------------------------------------------\n",
    "#Obtener los datos numéricos y categoricos\n",
    "\n",
    "cols_cat = datos.select_dtypes(include=['object']).columns\n",
    "cols_num = datos.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "print(f\"Los valores categoricos son: {cols_cat}\")\n",
    "print()\n",
    "print(f\"Los valores numericos son: {cols_num}\")\n",
    "    \n",
    "#------------------------------------------\n",
    "#Estudio de la correlación entre las variables numéricas\n",
    "\n",
    "X = datos.select_dtypes(include=['int64', 'float64'])\n",
    "df = pd.DataFrame(X)\n",
    "print()\n",
    "print(df)\n",
    "\n",
    "corr_matrix = df.corr().abs()\n",
    "print()\n",
    "print(corr_matrix)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "plt.title('Correlación entre variables', y=1, size=16)\n",
    "sns.heatmap(corr_matrix, vmax=.8, square=True)\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "print()\n",
    "print(upper)\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print()\n",
    "print(\"Estos son los atributos a eliminar:\\n\")\n",
    "print(to_drop)\n",
    "\n",
    "#------------------------------------------\n",
    "#Drop the los valores que no se van a utilizar o no pertenecen al dataset\n",
    "cols_cat = cols_cat.drop('Over18')\n",
    "cols_cat = cols_cat.drop('Attrition')\n",
    "cols_num = cols_num.drop('EmployeeCount')\n",
    "cols_num = cols_num.drop('StandardHours')\n",
    "cols_num = cols_num.drop('EmployeeID')\n",
    "\n",
    "col_cat = []\n",
    "col_num = []\n",
    "for i in cols_cat:\n",
    "    col_cat.append(str(i))\n",
    "for i in cols_num:\n",
    "    col_num.append(str(i))\n",
    "\n",
    "# Define the transformers\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, col_num),\n",
    "    ('cat', categorical_transformer, col_cat),\n",
    "    \n",
    "])\n",
    "\n",
    "print()\n",
    "print(\"Preprocesador para usar en los modelos debido a la cantidad de missing values | NaN:\\n\")\n",
    "print(preprocessor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que se trata de un problema de clasificación desbalanceado, por lo que se debe tener en cuenta a la hora de evaluar los modelos. Además, se debe tener en cuenta que el objetivo es predecir si un empleado se va a ir de la empresa o no por lo que lo haremos con métricas como f1_score, balanced_accuracy y una matrix de confusión. Como conclusión del EDA, los atributos Over18, EmployeeCount, StandardHours son valores constantes por lo que se han de eliminar de los datos, además el atributo EmployeeID no tiene ninguna relevancia para el modelo. Para tratar la falta de datos y otros se ha planteado un preprocesado de datos que se encuentra al final del estudio. Este preproceso realiza una imputación simple sobre los atributos, siendo la media para los numéricos y los más frecuentes para los categóricos. Por otro lado, hemos considerado aplicar un OneHotEncoder a los atributos categóricos para que los modelos puedan trabajar con ellos. De la misma forma se debe aplicar al target por lo que hemos optado por hacer un reemplazo de valores al extraer los conjuntos que se verán ahora. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Construcción de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extracción del conjunto de datos train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "#Se realizará la exrtacción de los datos de entrenamiento y test con el preprocesador obtenido en el EDA\n",
    "datos = pd.read_pickle('./attrition_available_9.pkl')\n",
    "target = datos['Attrition']\n",
    "datos.drop(columns=['Attrition','Over18','EmployeeCount','StandardHours','EmployeeID'], inplace=True)\n",
    "target = target.replace({'Yes': 1, 'No': 0})\n",
    "original_columns = pd.get_dummies(datos).columns\n",
    "data = pd.DataFrame(preprocessor.fit_transform(datos))\n",
    "\n",
    "\n",
    "#Se reparte el dataset en X y y\n",
    "ds = data.T\n",
    "X = [] \n",
    "y = target.T.tolist()\n",
    "for i in ds.columns:\n",
    "    X.append(ds[i].tolist())\n",
    "\n",
    "#------------------------------------------\n",
    "#Obtenemos los conjuntos de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Que se tendrá en cuenta a la hora de evaluar los modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por una parte, se ha de tener en cuenta que se trata de un problema de clasificación desbalanceado, por lo que se debe tener en cuenta a la hora de evaluar los modelos. Además, se debe tener en cuenta que el objetivo es predecir si un empleado se va a ir de la empresa o no por lo que lo haremos con métricas como f1_score, balanced_accuracy y una matrix de confusión. Por lo que estas métricas serán las que se tendrán en cuenta a la hora de evaluar los modelos y por la que se elegirá el mejor modelo. Es importante saber de manera teórica por qué se elige un modelo en base a estas métricas. \n",
    "\n",
    "En F1 score, si nuestro resultado es un valor alto cercano a 1 indica que el modelo ha alcanzado un buen equilibrio entre precision y recall, identificando de manera correcta instancias tanto positivas como negativas. Esto se considera como una salida deseada, particularmente para este tipo de problema. Si está por encima de 0.5 se sugiere that que el modelo esta funcionando razonadamente bien. El modelo estaría alcanzando un buen equilibrio entre precision y recall, aunque podría mejorarse. Si está cerca de 0.5 el funcionamiento es mediocre y no estaría funcionando mejor que un random guessing. Si está por debajo de 0.5 el modelo funciona mal y podría estar teniendo problema para clasificar instancias correctamente y podría estar sesgado hacia una clase o sufrir errores significativos. \n",
    "\n",
    "En balanced accuracy, si nuestro resultado es un valor alto cercano a 1 indica que el modelo funciona bien en términos de clasificar correctamente las clases mayoritarias y minoritarias. Si está por encima de 0.5 el modelo funciona mejor que un random guessing, es decir, hace predicciones precisas aunque haya alguna diferencia de funcinamiento entre clases. Si está cerca de 0.5 el funcionamiento es mediocre y no estaría funcionando mejor que un random guessing y podría estar sesgado hacia una clase. Si está por debajo de 0.5 el modelo funciona mal y podría estar teniendo problema para clasificar instancias correctamente y podría estar sesgado hacia una clase.\n",
    "\n",
    "En una matriz de confusión se puede resumir el funcionamiento de un modelo de clasificación mostrando la cuenta de 'true positives' (TP-número de instancias positivas predictas correctamente), 'true negatives' (TN-número de instancias negativas predictas correctamente), 'false positives'(FP-número de instancias positivas predictas incorrectamente) y 'false negatives'(FN-número de instancias negativas predictas incorrectamente). Con estos se puede clacular el accuracy ((TP + TN) / (TP + TN + FP + FN)), precision (TP / (TP + FP)), recall (TP / (TP + FN)) y f1 score (2 * (precision * recall) / (precision + recall)). Con la matriz de confusión se puede tener una visión más clara de cómo funciona el modelo, por lo que se puede analizar las clases con sus fuertes. Con las distribuciones de esta matriz se puede ver si el modelo está sesgado hacia alguna clase o si tiene problemas para clasificar instancias correctamente.\n",
    "\n",
    "Por otro lado, evaluar los modelos con validaciones cruzadas. En nuestro caso se ha propuesto GridSearchCV, RandomizedSearchCV y BayesSearchCV. Se ha decidido probar el método de Grid Search ya que realiza una búsqueda exhaustiva de todos los posibles valores de hiper parámetros especificados además de evaluar el rendimiento del modelo para cada combinación de estos. Por otro lado, Bayes Search encuentra la combinación de hiper parámetros óptima y puede ser especialmente útil si se trata de ajustar muchos hiper parámetros sin realizar una búsqueda exhaustiva de todas las combinaciones. Finalmente, Random Search consideramos que es uno de los más útiles al no conocer los valores óptimos de los hiper parámetros. Este modelo es perfecto al tener un enfoque más exploratorio realizando una búsqueda aleatoria en un rango de valores de cada hiper parámetro y evalúa el rendimiento de este para cada combinación aleatoria.\n",
    "\n",
    "Los modelos de Boosting que se han elegido son HistGradientBoosting de scikit learn y LightGBM como librería externa. Se ha escogido HistGradientBoosting por ser bueno debido a su eficiencia computacional, manejo eficiente de datos categóricos, menor consumo de memoria, buen rendimiento predictivo y su compatibilidad con la biblioteca scikit-learn. Por otro lado, se ha elegido LightGBM por que es una biblioteca de gradient boosting conocida por su eficiencia, velocidad y capacidad para manejar conjuntos de datos grandes. Ofrece un rendimiento predictivo superior, flexibilidad para personalizar el modelo y es compatible con varias plataformas. Es una opción popular para problemas de aprendizaje automático que requieren modelos precisos y rápidos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 1: Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Logistic Regression\n",
    "#--------------------------------------\n",
    "\n",
    "inicio = time.time()\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegression(random_state=9, class_weight='balanced')\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "pipe_clf.fit(X_train, y_train)\n",
    "y_pred = pipe_clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "print(f\"El tiempo tardado es de {tiempo} segundos.\\n\")\n",
    "print(f\"El f1 es de {f1}\\n\")\n",
    "print(f\"El balanced accuracy es de {bal_acc}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Logistic Regression\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = { 'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LogisticRegression(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LogisticRegression(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None]}\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "b_clf = LogisticRegression(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de Regresión Logística es el primero, el cual no incluye ninguna validación cruzada a pesar de que es un modelo malo por sus resultados en las métricas escogidas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2: Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.1: Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = { 'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': [ 10, 15, 20 ],\n",
    "         'clf__learning_rate': [10, 1, 0.1]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=15),\n",
    "         'clf__learning_rate': uniform( 0.1, 1)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': Integer(low=10, high=20, name='clf__max_depth'),\n",
    "         'clf__learning_rate': Real(low=0.1, high=1, prior='log-uniform', name='clf__learning_rate')}\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de HistGradientBoosting es el modelo con RandomizedSearchCV. Este modelo ha tenido competencia con GridSearchCV en cuestión a tiempo y métrica, pero al presentar un menor tiempo por algún segundo y tener algún porcentaje mayor que otro Random Search es la mejor opción. Bayes Search no ha sido una opción ya que ha tardado mucho más que los otros y no es que presentase mejoras notables. A continuación, se muestra el modelo con RandomizedSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=15),\n",
    "         'clf__learning_rate': uniform( 0.1, 1),\n",
    "         'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.2: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [1500, 2000, 2500],\n",
    "              'clf__learning_rate': [0.1, 1],\n",
    "              'clf__max_depth': [15, 20, 25],\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(2000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.001, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(2000, 3000),\n",
    "              'clf__learning_rate': Real(0.1, 1, prior='log-uniform'),\n",
    "              'clf__max_depth': Integer(10, 30)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(X_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de LightGBM es con RandomizedSearchCV. Este modelo ha sido seleccionado por su tiempo ya que tardaba menos en comparación a los demás y aunque los demás presentarán algún cambio en los resultados no han sido significativos como para ser seleccionados. A continuación, se muestra el modelo con RandomizedSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(2000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.001, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None],\n",
    "              'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = LGBMClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modelos con atributos de tipo filtro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos SelectKBest sobre 10 para aplicar filtros a los atributos. Esta aplicación unicamente se aplica sobre los de entrenamiento y no a todos los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Datos con atributos de tipo filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "#Conjuntos para f_classif\n",
    "selector_f_classif = SelectKBest(f_classif, k=10)\n",
    "Z_train = selector_f_classif.fit_transform(X_train, y_train)\n",
    "Z_test = selector_f_classif.fit_transform(X_test, y_test)\n",
    "\n",
    "#------------------------------------------\n",
    "#Conjuntos para mutual_info_classif\n",
    "selector_mutual_info_classif = SelectKBest(mutual_info_classif, k=10)\n",
    "W_train = selector_mutual_info_classif.fit_transform(X_train, y_train)\n",
    "W_test = selector_mutual_info_classif.fit_transform(X_test, y_test)\n",
    "\n",
    "#------------------------------------------\n",
    "#Conjuntos para chi2\n",
    "selector_chi2_classif = SelectKBest(chi2, k=10)\n",
    "V_train = selector_chi2_classif.fit_transform(X_train, y_train)\n",
    "V_test = selector_chi2_classif.fit_transform(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelos con atributos de tipo filtro f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = { 'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': [10, 15, 20],\n",
    "         'clf__learning_rate': [10, 1, 0.1]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(Z_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=20),\n",
    "         'clf__learning_rate': uniform(0.01, 1)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(Z_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': Integer(low=20, high=70, name='clf__max_depth'),\n",
    "         'clf__learning_rate': Real(low=0.01, high=10, prior='log-uniform', name='clf__learning_rate')}\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(Z_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de HistGradientBoosting con filtro de f_classif es con GridSearchCV. Como pasará en todos los modelos Bayes Search tiene tiempos muy elevados y es por eso que se descarta. En cuanto a Random Search, presenta un tiempo y resultados muy similares a Random Search por lo que la decisión ha estado con nostros y la matriz de confusión. A continuación, se muestra el modelo con RandomizedSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': [10, 15, 20],\n",
    "         'clf__learning_rate': [10, 1, 0.1],\n",
    "         'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = GridSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "y_pred = clf.predict(Z_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [2000, 3000],\n",
    "              'clf__learning_rate': [0.1, 1, 10],\n",
    "              'clf__max_depth': [10, 15, 20],\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(Z_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(1000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.01, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(Z_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(1000, 3000),\n",
    "              'clf__learning_rate': Real(0.1, 1, prior='log-uniform'),\n",
    "              'clf__max_depth': Integer(10, 20)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(Z_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(Z_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de LightGBM con filtro de f_classif es con Grid Search. Bayes Search es modelo que descartamos por tiempo. En cuanto a Random Search, este presenta un tiempo mucho menor y resultados muy similares a Grid Search, pero ha influenciado en la decisión ha sido la matriz de confusión que a diferencia de otros casos anteriores hay un diferencia notable en la que Grid Search es mejor. A continuación, se muestra el modelo con GridSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [2000, 3000],\n",
    "              'clf__learning_rate': [0.1, 1, 10],\n",
    "              'clf__max_depth': [10, 15, 20],\n",
    "              'clf__class_weight': ['balanced', None],\n",
    "              'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = LGBMClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = GridSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(Z_train, y_train)\n",
    "y_pred = clf.predict(Z_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelos con atributos de tipo filtro mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = { 'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': [10, 15, 20],\n",
    "         'clf__learning_rate': [10, 1, 0.1]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(W_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=20),\n",
    "         'clf__learning_rate': uniform(0.01, 1)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(W_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': Integer(low=10, high=20, name='clf__max_depth'),\n",
    "         'clf__learning_rate': Real(low=0.01, high=1, prior='log-uniform', name='clf__learning_rate')}\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(W_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de HistGradientBoosting con filtro de mutual_info_classf es con RandomSeacrhCV. Bayes Search descartado por sus enormes tiempos. Grid Search y Random Search presentan tiempos y resultados muy similares, pero la matriz de confusión ha sido la que ha influenciado en la decisión. A continuación, se muestra el modelo con RandomSeacrhCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = { 'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=20),\n",
    "         'clf__learning_rate': uniform(0.01, 1),\n",
    "         'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "y_pred = clf.predict(W_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [1000, 1500, 2000],\n",
    "              'clf__learning_rate': [0.01, 0.1, 1],\n",
    "              'clf__max_depth': [10, 15, 20],\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(W_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(1000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.01, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(W_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(500, 2000),\n",
    "              'clf__learning_rate': Real(0.01, 1, prior='log-uniform'),\n",
    "              'clf__max_depth': Integer(10, 20)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(W_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(W_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de LightGBM con filtro de mutual_info_classf es con RandomSearchCV. Bayes Search y Grid Search presentan tiempos muy altos por lo que se descartan inmediatamente ya que ninguno presenta mucha mejora en relación a Random Search. A continuación, se muestra el modelo con RandomizedSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(1000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.01, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None],\n",
    "              'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = LGBMClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(W_train, y_train)\n",
    "y_pred = clf.predict(W_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelos con atributos de tipo filtro chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = { 'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': [10, 15, 20],\n",
    "         'clf__learning_rate': [10, 1, 0.1]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(V_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=20),\n",
    "         'clf__learning_rate': uniform(0.1, 1)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(V_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': Integer(low=10, high=20, name='clf__max_depth'),\n",
    "         'clf__learning_rate': Real(low=0.1, high=1, prior='log-uniform', name='clf__learning_rate')}\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = HistGradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(V_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de HistGradientBoosting con filtro de chi2 es con RandomSearchCV. Bayes como se ha mencionado en muchas explicaciones no se toma en cuenta por sus tiempos. En cuanto a Grid Search y Random Search, presentan tiempos y resultados muy similares, pero la matriz de confusión ha sido la que ha influenciado en la decisión. A continuación, se muestra el modelo con RandomizedSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=20),\n",
    "         'clf__learning_rate': uniform(0.1, 1),\n",
    "         'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = StandardScaler()\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "y_pred = clf.predict(V_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [250, 500, 1000],\n",
    "              'clf__learning_rate': [0.1, 1, 10],\n",
    "              'clf__max_depth': [10, 15, 20],\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(V_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(1000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.1, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_f1.predict(V_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(1000, 3000),\n",
    "              'clf__learning_rate': Real(0.01, 1, prior='log-uniform'),\n",
    "              'clf__max_depth': Integer(10, 20)}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param, cv=inner, scoring='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(V_train, y_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "inicio = time.time()\n",
    "y_pred = clf_bal_acc.predict(V_test)\n",
    "clf_cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_conf_matrix} segundos para confusión matrix.\\n\")\n",
    "print(f\"El confusion matrix es de: \\n{clf_cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las pruebas y evaluaciones realizadas se ha decidido que el mejor modelo de LightGBM con filtro de chi2 es con RandomSearchCV. Bayes Search presenta tiempos muy elevados. En cuanto a Grid Search y Random Search, presentan tiempos y resultados muy similares, pero el tiempo en este caso ha sido la que ha influenciado en la decisión. A continuación, se muestra el modelo con RandomizedSearchCV en un versión de Pipeline mejorada, se tendrá que cambiar 'refit' para conocer los mejores resultados y parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(1000, 3000),\n",
    "              'clf__learning_rate': loguniform(0.1, 1),\n",
    "              'clf__max_depth': randint(10, 20),\n",
    "              'clf__class_weight': ['balanced', None],\n",
    "              'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = LGBMClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "inicio = time.time()\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(V_train, y_train)\n",
    "y_pred = clf.predict(V_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "\n",
    "print(f\"\\nEl tiempo tardado es de {tiempo} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf.best_score_} con estimadores {clf.best_estimator_}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusiones y comparación de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por las conclusiones sacadas de cada tipo de modelo con sus características la regresión logística es nefasta en relación a los demás modelos por lo que no será el modelo final. En el caso de boosting se han comprobado y comparado los resultados de HistGradientBoosting con y sin filtro y por lo que se ha visto el mejor es sin filtros, esto es porque algunos o la mayoría presentaban mejores tiempos pero a la hora de comparar resultados de las métricas o se parecían bastante pero la matriz era mucho peor o presentaban peores resultados es por eso que el vencedor este modelo sin filtro. De la misma manera a ocurrido al comparar las distintas versiones para el modelo de LightGBM y se concluye que es mejor sin filtros. Ahora la desición entre estos dos es complicada ya que ambos presentan resultados similares en todas las métricas por lo que nos guiaremos por el tiempo tardado. En este cosa y bajo este criterio será HistGradientBoosting con RandomSearchCV el modelo final.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, queremos mencionar que hemos tenido problemas para poder añadir el preproceso de datos en las pipelines de los modelos por lo que he lo hemos hecho al principio sobre todo el conjunto de datos. Sabemos que los hiperparámetros escogidos no sean los mejores para dichos modelos pero tras una serie de evaluaciones no hemos decantado por los que se muestran en el notebook. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Final Model with HistGradientBoostingClassifier RandomizedSearchCV\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': ['balanced', None],\n",
    "         'clf__max_depth': randint(low=10, high=15),\n",
    "         'clf__learning_rate': uniform( 0.1, 1),\n",
    "         'clf__random_state': [9]}\n",
    "\n",
    "inner = StratifiedKFold(n_splits=10, shuffle=True, random_state=9)\n",
    "scaler = RobustScaler()\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "clf = HistGradientBoostingClassifier()\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "clf = RandomizedSearchCV(pipe_clf, param, cv=inner, scoring=scoring, refit='f1', n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "#--------------------------------------\n",
    "# Passing the model to pickle\n",
    "#--------------------------------------\n",
    "with open('modelo_final.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grupo 9 Práctica 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prerequisitos:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.9.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-optimize) (1.2.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-optimize) (1.10.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement skopt (from versions: none)\n",
      "ERROR: No matching distribution found for skopt\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.13.5)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from statsmodels) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from statsmodels) (23.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n",
      "Requirement already satisfied: six in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (0.40.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\aalex\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\aalex\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install pandas\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install scikit-optimize\n",
    "!pip3 install skopt\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install statsmodels\n",
    "!pip3 install lightgbm\n",
    "!pip3 install xgboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble, tree, linear_model\n",
    "import time\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier #CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from skopt.space import Integer, Real, Categorical\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_pickle('./attrition_available_9.pkl')\n",
    "target = datos['Attrition']\n",
    "data = datos.drop(columns=['Attrition'])\n",
    "#------------------------------------------\n",
    "#Encodear variables categoricas\n",
    "#------------------------------------------\n",
    "data_encoded = pd.get_dummies(data)\n",
    "ds = data_encoded.T\n",
    "X = [] \n",
    "y = target.T.tolist()\n",
    "for i in ds.columns:\n",
    "    X.append(ds[i].tolist())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos.head())\n",
    "print(datos.info())\n",
    "print(datos['Attrition'].value_counts(normalize=True))\n",
    "print(datos.isnull().sum())\n",
    "\n",
    "datos_no_na = datos.dropna()\n",
    "datos_no_na.fillna(datos_no_na['cat_var'].mode()[0], inplace=True)\n",
    "datos_no_na.fillna(datos_no_na['num_var'].median(), inplace=True)\n",
    "\n",
    "pos_class = datos_no_na[datos_no_na['Attrition'] == 1]\n",
    "neg_class = datos_no_na[datos_no_na['Attrition'] == 0]\n",
    "\n",
    "pos_class_upsampled = pos_class.sample(pos_class, n=len(neg_class), replace=True, random_state=42)\n",
    "\n",
    "datos_balanced = pd.concat([pos_class_upsampled, neg_class])\n",
    "datos_balanced = datos_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "sns.pairplot(datos_balanced, hue='Attrition', palette='Set1')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='Attrition', y='Age', data=datos_balanced)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='cat_var', hue='Attrition', data=datos_balanced)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que se trata de un problema de clasificación desbalanceado, por lo que se debe tener en cuenta a la hora de evaluar los modelos. Además, se debe tener en cuenta que el objetivo es predecir si un empleado se va a ir de la empresa o no, por lo que se debe tener en cuenta que la métrica a utilizar es la precisión. Missing values, se debe imputar los datos, y se debe utilizar una partición estratificada. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Construcción de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extracción del conjunto de datos train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:2940]\n",
    "X_test = X[2940:]\n",
    "y_train = y[0:2940]\n",
    "y_test = y[2940:]\n",
    "X_train_train = X_train[0:1960]\n",
    "X_train_test = X_train[1960:]\n",
    "y_train_train = y_train[0:1960]\n",
    "y_train_test = y_train[1960:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 1: Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label. It should be one of ['No', 'Yes']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m pipe_clf\u001b[39m.\u001b[39mfit(X_train_train, y_train_train)\n\u001b[0;32m     11\u001b[0m y_pred \u001b[39m=\u001b[39m pipe_clf\u001b[39m.\u001b[39mpredict(X_train_test)\n\u001b[1;32m---> 12\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_train_test, y_pred)\n\u001b[0;32m     13\u001b[0m bal_acc \u001b[39m=\u001b[39m balanced_accuracy_score(y_train_test, y_pred)\n\u001b[0;32m     14\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_train_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     y_true,\n\u001b[0;32m   1013\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m ):\n\u001b[0;32m   1021\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1147\u001b[0m         y_true,\n\u001b[0;32m   1148\u001b[0m         y_pred,\n\u001b[0;32m   1149\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1150\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1151\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1152\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1153\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1154\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1155\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     y_true,\n\u001b[0;32m   1160\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1168\u001b[0m ):\n\u001b[0;32m   1169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \n\u001b[0;32m   1171\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1288\u001b[0m         y_true,\n\u001b[0;32m   1289\u001b[0m         y_pred,\n\u001b[0;32m   1290\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1291\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1292\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1293\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1294\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1295\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1296\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1297\u001b[0m     )\n\u001b[0;32m   1298\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1382\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \u001b[39mif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m present_labels:\n\u001b[0;32m   1381\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(present_labels) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1382\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1383\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpos_label=\u001b[39m\u001b[39m{\u001b[39;00mpos_label\u001b[39m}\u001b[39;00m\u001b[39m is not a valid label. It \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshould be one of \u001b[39m\u001b[39m{\u001b[39;00mpresent_labels\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m     labels \u001b[39m=\u001b[39m [pos_label]\n\u001b[0;32m   1387\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']"
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# Logistic Regression\n",
    "#--------------------------------------\n",
    "\n",
    "inicio = time.time()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegression(random_state=9, class_weight='balanced')\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', clf)])\n",
    "pipe_clf.fit(X_train_train, y_train_train)\n",
    "y_pred = pipe_clf.predict(X_train_test)\n",
    "f1 = f1_score(y_train_test, y_pred)\n",
    "bal_acc = balanced_accuracy_score(y_train_test, y_pred)\n",
    "cm = confusion_matrix(y_train_test, y_pred)\n",
    "final = time.time()\n",
    "tiempo = final - inicio\n",
    "print(f\"El tiempo tardado es de {tiempo} segundos.\\n\")\n",
    "print(f\"El f1 es de {f1}\\n\")\n",
    "print(f\"El balanced accuracy es de {bal_acc}\\n\")\n",
    "print(f\"La matriz de confusión es: \\n{cm}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Logistic Regression\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2: Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.1: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m pipe_clf \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mimputer\u001b[39m\u001b[39m'\u001b[39m, imputer), (\u001b[39m'\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m'\u001b[39m, scaler), (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, b_clf)])\n\u001b[0;32m     19\u001b[0m inicio \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 20\u001b[0m clf_f1 \u001b[39m=\u001b[39m GridSearchCV(pipe_clf, param_grid\u001b[39m=\u001b[39;49mparam, cv\u001b[39m=\u001b[39;49minner, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X_train_train, y_train_train)\n\u001b[0;32m     21\u001b[0m final \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     22\u001b[0m tiempo_f1 \u001b[39m=\u001b[39m final \u001b[39m-\u001b[39m inicio\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {\n",
    "         'clf__max_depth': [3, 5, 7],\n",
    "         'clf__learning_rate': [0.1, 0.01, 0.001],\n",
    "         'clf__subsample': [0.5, 0.8, 1.0],\n",
    "         'clf__max_features': ['sqrt', 'log2', None],\n",
    "         'clf__n_estimators': [100, 500, 1000],\n",
    "         'clf__min_samples_split': [2, 5, 10],\n",
    "         'clf__min_samples_leaf': [1, 2, 4],\n",
    "         'clf__min_weight_fraction_leaf': [0.0, 0.1, 0.2]}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = GradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo tardado es de 11.130460739135742 segundos para f1.\n",
      "\n",
      "El f1 es de nan con estimadores Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', None),\n",
      "                ('clf',\n",
      "                 GradientBoostingClassifier(learning_rate=0.08124296260447306,\n",
      "                                            max_depth=9, max_features='sqrt',\n",
      "                                            min_samples_split=17,\n",
      "                                            min_weight_fraction_leaf=0.10192161971328487,\n",
      "                                            n_estimators=299, random_state=9,\n",
      "                                            subsample=0.7592531456212814))])\n",
      "\n",
      "El tiempo tardado es de 9.185398578643799 segundos para balanced accuracy.\n",
      "\n",
      "El balanced accuracy es de 0.8469711385283081 con estimadores Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', None),\n",
      "                ('clf',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07774173405764452,\n",
      "                                            max_depth=4, max_features='sqrt',\n",
      "                                            min_samples_split=4,\n",
      "                                            min_weight_fraction_leaf=0.0160661223476412,\n",
      "                                            n_estimators=902, random_state=9,\n",
      "                                            subsample=0.7732565319761433))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {\n",
    "         'clf__max_depth': randint(low=3, high=10),\n",
    "         'clf__learning_rate': uniform(0.001, 0.1),\n",
    "         'clf__subsample': uniform(0.5, 0.5),\n",
    "         'clf__max_features': ['sqrt', 'log2', None],\n",
    "         'clf__n_estimators': randint(low=100, high=1000),\n",
    "         'clf__min_samples_split': randint(low=2, high=20),\n",
    "         'clf__min_samples_leaf': randint(low=1, high=5),\n",
    "         'clf__min_weight_fraction_leaf': uniform(0.0, 0.2)}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = GradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__class_weight': Categorical(categories=['balanced', None], name='clf__class_weight'),\n",
    "         'clf__max_depth': Integer(low=3, high=10, name='clf__max_depth'),\n",
    "         'clf__learning_rate': Real(low=0.001, high=0.1, prior='log-uniform', name='clf__learning_rate'),\n",
    "         'clf__subsample': Real(low=0.5, high=1.0, prior='uniform', name='clf__subsample'),\n",
    "         'clf__max_features': Categorical(categories=['sqrt', 'log2', None], name='clf__max_features'),\n",
    "         'clf__n_estimators': Integer(low=100, high=1000, name='clf__n_estimators'),\n",
    "         'clf__min_samples_split': Integer(low=2, high=20, name='clf__min_samples_split'),\n",
    "         'clf__min_samples_leaf': Integer(low=1, high=5, name='clf__min_samples_leaf'),\n",
    "         'clf__min_weight_fraction_leaf': Real(low=0.0, high=0.2, prior='uniform', name='clf__min_weight_fraction_leaf')}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = GradientBoostingClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.2: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo tardado es de 11.205840349197388 segundos para f1.\n",
      "\n",
      "El f1 es de nan con estimadores Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', None),\n",
      "                ('clf',\n",
      "                 LGBMClassifier(class_weight='balanced', learning_rate=0.01,\n",
      "                                max_depth=3, n_estimators=50, random_state=42,\n",
      "                                scale_pos_weight=1))])\n",
      "\n",
      "El tiempo tardado es de 9.270069599151611 segundos para balanced accuracy.\n",
      "\n",
      "El balanced accuracy es de 0.8486382851607356 con estimadores Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', None),\n",
      "                ('clf',\n",
      "                 LGBMClassifier(class_weight='balanced', max_depth=7,\n",
      "                                n_estimators=500, random_state=42,\n",
      "                                scale_pos_weight=25))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [50, 100, 500],\n",
    "              'clf__learning_rate': [0.01, 0.1, 1],\n",
    "              'clf__max_depth': [3, 5, 7],\n",
    "              'clf__scale_pos_weight': [1, 10, 25, 50],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__class_weight': ['balanced']}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo tardado es de 1.1591265201568604 segundos para f1.\n",
      "\n",
      "El f1 es de nan con estimadores Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', None),\n",
      "                ('clf',\n",
      "                 LGBMClassifier(class_weight='balanced',\n",
      "                                learning_rate=0.026241738888884116, max_depth=3,\n",
      "                                n_estimators=408, random_state=42,\n",
      "                                scale_pos_weight=10))])\n",
      "\n",
      "El tiempo tardado es de 1.1525464057922363 segundos para balanced accuracy.\n",
      "\n",
      "El balanced accuracy es de 0.8444786821075299 con estimadores Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', None),\n",
      "                ('clf',\n",
      "                 LGBMClassifier(class_weight='balanced',\n",
      "                                learning_rate=0.2889166424774813, max_depth=4,\n",
      "                                n_estimators=455, random_state=42,\n",
      "                                scale_pos_weight=1))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(50, 500),\n",
    "              'clf__learning_rate': loguniform(0.001, 1),\n",
    "              'clf__max_depth': randint(3, 7),\n",
    "              'clf__scale_pos_weight': [1, 10, 25, 50],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__class_weight': ['balanced']}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_distributions=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(50, 500),\n",
    "              'clf__learning_rate': Real(0.001, 1, prior='log-uniform'),\n",
    "              'clf__max_depth': Integer(3, 7),\n",
    "              'clf__scale_pos_weight': Categorical([1, 10, 25, 50]),\n",
    "              'clf__random_state': Constant(42),\n",
    "              'clf__class_weight': Categorical(['balanced'])}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = LGBMClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with XGBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [50, 100, 500],\n",
    "              'clf__learning_rate': [0.01, 0.1, 1],\n",
    "              'clf__max_depth': [3, 5, 7],\n",
    "              'clf__scale_pos_weight': [1, 10, 25, 50],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__class_weight': ['balanced']}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = XGBClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with XGBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with XGBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(50, 500),\n",
    "              'clf__learning_rate': loguniform(0.001, 1),\n",
    "              'clf__max_depth': randint(3, 7),\n",
    "              'clf__scale_pos_weight': [1, 10, 25, 50],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__class_weight': ['balanced']}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = XGBClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with XGBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with XGBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(50, 500),\n",
    "              'clf__learning_rate': Real(0.001, 1, prior='log-uniform'),\n",
    "              'clf__max_depth': Integer(3, 7),\n",
    "              'clf__scale_pos_weight': Categorical([1, 10, 25, 50]),\n",
    "              'clf__random_state': Constant(42),\n",
    "              'clf__class_weight': Categorical(['balanced'])}\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = XGBClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('imputer', imputer), ('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with XGBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.4: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with CatBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__learning_rate': [0.01, 0.1, 1],\n",
    "              'clf__n_estimators': [100, 500, 1000],\n",
    "              'clf__max_depth': [3, 5, 7],\n",
    "              'clf__class_weights': ['balanced']}\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = CatBoostClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with CatBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with CatBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__learning_rate': loguniform(0.001, 1),\n",
    "              'clf__n_estimators': randint(100, 1000),\n",
    "              'clf__max_depth': randint(3, 7),\n",
    "              'clf__class_weights': ['balanced']}\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = CatBoostClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with CatBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with CatBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__learning_rate': Real(0.001, 1, prior='log-uniform'),\n",
    "              'clf__n_estimators': Integer(100, 1000),\n",
    "              'clf__max_depth': Integer(3, 7),\n",
    "              'clf__class_weights': Categorical(['balanced'])}\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = CatBoostClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with CatBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2.5: AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with AdaBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': [50, 100, 500],\n",
    "              'clf__learning_rate': [0.01, 0.1, 1],\n",
    "              'clf__algorithm': ['SAMME', 'SAMME.R'],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__class_weight': ['balanced']}\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = AdaBoostClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = GridSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with AdaBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with AdaBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': randint(50, 500),\n",
    "              'clf__learning_rate': loguniform(0.001, 1),\n",
    "              'clf__algorithm': ['SAMME', 'SAMME.R'],\n",
    "              'clf__random_state': [42],\n",
    "              'clf__class_weight': ['balanced']}\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = AdaBoostClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = RandomizedSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with AdaBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with AdaBoost with Hyperparameter Tuning\n",
    "#--------------------------------------\n",
    "\n",
    "param = {'clf__n_estimators': Integer(50, 500),\n",
    "              'clf__learning_rate': Real(0.001, 1, prior='log-uniform'),\n",
    "              'clf__algorithm': Categorical(['SAMME', 'SAMME.R']),\n",
    "              'clf__random_state': Constant(42),\n",
    "              'clf__class_weight': Categorical(['balanced'])}\n",
    "inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)\n",
    "scaler = None\n",
    "b_clf = AdaBoostClassifier(random_state=9)\n",
    "pipe_clf = Pipeline([('scaler', scaler), ('clf', b_clf)])\n",
    "inicio = time.time()\n",
    "clf_f1 = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring='f1', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_f1 = final - inicio\n",
    "inicio = time.time()\n",
    "clf_bal_acc = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= 'balanced_accuracy', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "final = time.time()\n",
    "tiempo_bal_acc = final - inicio\n",
    "# inicio = time.time()\n",
    "# clf_conf_matrix = BayesSearchCV(pipe_clf, param_grid=param, cv=inner, scoring= '', n_jobs=-1).fit(X_train_train, y_train_train)\n",
    "# final = time.time()\n",
    "# tiempo_conf_matrix = final - inicio\n",
    "\n",
    "print(f\"El tiempo tardado es de {tiempo_f1} segundos para f1.\\n\")\n",
    "print(f\"El f1 es de {clf_f1.best_score_} con estimadores {clf_f1.best_estimator_}\\n\")\n",
    "print(f\"El tiempo tardado es de {tiempo_bal_acc} segundos para balanced accuracy.\\n\")\n",
    "print(f\"El balanced accuracy es de {clf_bal_acc.best_score_} con estimadores {clf_bal_acc.best_estimator_}\\n\")\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with AdaBoost with Hyperparameter Tuning\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modelo con atributos de tipo filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with Hyperparameter Tuning with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with LightGBM with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with XGBoost with filter\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with XGBoost with filter\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modelos con EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 1: Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Logistic Regression after EDA\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "# Logistic Regression after EDA\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Modelo 2: Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# Boosting with (...) after EDA\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------\n",
    "# Boosting with (...) after EDA\n",
    "#--------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusiones y comparación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
